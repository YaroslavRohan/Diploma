{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport warnings\nfrom pathlib import Path\nfrom tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Dropout, Conv2D, MaxPool2D, BatchNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.applications.vgg19 import preprocess_input\nfrom tensorflow.keras.preprocessing import image, image_dataset_from_directory\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow import keras\nimport tensorflow \nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\nfrom keras.utils.vis_utils import plot_model\nfrom sklearn.metrics import matthews_corrcoef as MCC\nfrom sklearn.metrics import balanced_accuracy_score as BAS\n\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    \"/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train\",\n    validation_split=0.2,\n    subset=\"training\",\n    seed=1337,\n    image_size=[180, 180],\n    batch_size=16,\n)\n\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    \"/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train\",\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=1337,\n    image_size=[180, 180],\n    batch_size=16 ,\n)\n\ntest_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    \"/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test\",\n    seed=1337,\n    image_size=[180, 180],\n    batch_size=16 ,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classnames = train_ds.class_names\nlen(classnames),train_ds.class_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CLASSES = [ 'NonDemented',\n            'VeryMildDemented',\n            'MildDemented',\n            'ModerateDemented']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_IMAGES = []\n\nfor label in classnames:\n    dir_name = \"/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/\" + label[:-2] +'ed'\n    NUM_IMAGES.append(len([name for name in os.listdir(dir_name)]))\n    \nNUM_IMAGES,classnames","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.bar(classnames, NUM_IMAGES)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Performing Image Augmentation to have more data samples\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator as IDG\nIMG_SIZE = 180\nIMAGE_SIZE = [180, 180]\nDIM = (IMG_SIZE, IMG_SIZE)\nZOOM = [.99, 1.01]\nBRIGHT_RANGE = [0.8, 1.2]\nHORZ_FLIP = True\nFILL_MODE = \"constant\"\nDATA_FORMAT = \"channels_last\"\nWORK_DIR=\"/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train\"\nwork_dr = IDG(rescale = 1./255, brightness_range=BRIGHT_RANGE, zoom_range=ZOOM, data_format=DATA_FORMAT, fill_mode=FILL_MODE, horizontal_flip=HORZ_FLIP)\n\ntrain_data_gen = work_dr.flow_from_directory(directory=WORK_DIR, target_size=DIM, batch_size=6500, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data, train_labels = train_data_gen.next()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#before oversampling\nprint(train_data.shape, train_labels.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Performing over-sampling of the data, since the classes are imbalanced\n#after oversampling\nfrom imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state=42)\n\ntrain_data, train_labels = sm.fit_resample(train_data.reshape(-1, IMG_SIZE * IMG_SIZE * 3), train_labels)\n\ntrain_data = train_data.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n\nprint(train_data.shape, train_labels.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Splitting the data into train, test, and validation sets\nfrom sklearn.model_selection import train_test_split\ntrain_data, test_data, train_labels, test_labels = train_test_split(train_data, train_labels, test_size = 0.2, random_state=42)\ntrain_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size = 0.2, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Inception**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.inception_v3 import InceptionV3\ninception_model = InceptionV3(input_shape=(180, 180, 3), include_top=False, weights=\"imagenet\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer in inception_model.layers:\n    layer.trainable=False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import SeparableConv2D, BatchNormalization, GlobalAveragePooling2D\ncustom_inception_model = Sequential([\n        inception_model,\n        Dropout(0.5),\n        GlobalAveragePooling2D(),\n        Flatten(),\n        BatchNormalization(),\n        Dense(512, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.5),\n        Dense(256, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.5),\n        Dense(128, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.5),\n        Dense(64, activation='relu'),\n        Dropout(0.5),\n        BatchNormalization(),\n        Dense(4, activation='softmax')        \n    ], name = \"inception_cnn_model\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Defining a custom callback function to stop training our model when accuracy goes above 99%\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\nclass MyCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if logs.get('acc') > 0.99:\n            print(\"\\nReached accuracy threshold! Terminating training.\")\n            self.model.stop_training = True\n            \nmy_callback = MyCallback()\n\n#ReduceLROnPlateau to stabilize the training process of the model\nrop_callback = ReduceLROnPlateau(monitor=\"val_loss\", patience=3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"METRICS = [tf.keras.metrics.CategoricalAccuracy(name='acc'),\n           tf.keras.metrics.AUC(name='auc')]\n\nCALLBACKS = [my_callback, rop_callback]\n    \ncustom_inception_model.compile(optimizer='rmsprop',\n                              loss=tf.losses.CategoricalCrossentropy(),\n                              metrics=METRICS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fit the training data to the model and validate it using the validation data\nEPOCHS = 50\n\nhistory = custom_inception_model.fit(train_data, train_labels, validation_data=(val_data, val_labels), callbacks=CALLBACKS, epochs=EPOCHS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_inception_model.save('/kaggle/working/inception_model', save_format='h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting the trend of the metrics during training\n\nfig, ax = plt.subplots(1, 3, figsize = (30, 5))\nax = ax.ravel()\n\nfor i, metric in enumerate([\"acc\", \"auc\", \"loss\"]):\n    ax[i].plot(history.history[metric])\n    ax[i].plot(history.history[\"val_\" + metric])\n    ax[i].set_title(\"Model {}\".format(metric))\n    ax[i].set_xlabel(\"Epochs\")\n    ax[i].set_ylabel(metric)\n    ax[i].legend([\"train\", \"val\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluating the model on the data\n\n#train_scores = model.evaluate(train_data, train_labels)\n# val_scores = model.evaluate(val_data, val_labels)\ntest_scores = custom_inception_model.evaluate(test_data, test_labels)\n\n#print(\"Training Accuracy: %.2f%%\"%(train_scores[1] * 100))\n# print(\"Validation Accuracy: %.2f%%\"%(val_scores[1] * 100))\nprint(\"Testing Accuracy: %.2f%%\"%(test_scores[1] * 100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_inception_model = current_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predicting the test data\n\npred_labels = custom_inception_model.predict(test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print the classification report of the tested data\n\n#Since the labels are softmax arrays, we need to roundoff to have it in the form of 0s and 1s,\n#similar to the test_labels\ndef roundoff(arr):\n    \"\"\"To round off according to the argmax of each predicted label array. \"\"\"\n    arr[np.argwhere(arr != arr.max())] = 0\n    arr[np.argwhere(arr == arr.max())] = 1\n    return arr\n\nfor labels in pred_labels:\n    labels = roundoff(labels)\n\nprint(classification_report(test_labels, pred_labels, target_names=CLASSES))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plot the confusion matrix to understand the classification in detail\n\npred_ls = np.argmax(pred_labels, axis=1)\ntest_ls = np.argmax(test_labels, axis=1)\n\nconf_arr = confusion_matrix(test_ls, pred_ls)\n\nplt.figure(figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n\nax = sns.heatmap(conf_arr, cmap='Reds', annot=True, fmt='d', xticklabels=CLASSES, yticklabels=CLASSES)\n\nplt.title('Dementia\\'s Diagnosis')\nplt.xlabel('Prediction')\nplt.ylabel('Truth')\nplt.show(ax)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Printing some other classification metrics\n\nprint(\"Balanced Accuracy Score: {} %\".format(round(BAS(test_ls, pred_ls) * 100, 2)))\nprint(\"Matthew's Correlation Coefficient: {} %\".format(round(MCC(test_ls, pred_ls) * 100, 2)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_dir = '/kaggle/input/models/inception_model'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"current_model = tf.keras.models.load_model(model_dir)\n\n#Check its architecture\n# plot_model(current_model, to_file=model_dir + '.png', show_shapes=True, show_layer_names=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Custom****","metadata":{}},{"cell_type":"code","source":"def conv_block(filters, act='relu'):\n    \"\"\"Defining a Convolutional NN block for a Sequential CNN model. \"\"\"\n    \n    block = Sequential()\n    block.add(Conv2D(filters, 3, activation=act, padding='same'))\n    block.add(Conv2D(filters, 3, activation=act, padding='same'))\n    block.add(BatchNormalization())\n    block.add(MaxPool2D())\n    \n    return block","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dense_block(units, dropout_rate, act='relu'):\n    \"\"\"Defining a Dense NN block for a Sequential CNN model. \"\"\"\n    \n    block = Sequential()\n    block.add(Dense(units, activation=act))\n    block.add(BatchNormalization())\n    block.add(Dropout(dropout_rate))\n    \n    return block","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def construct_model(act='relu'):\n    \"\"\"Constructing a Sequential CNN architecture for performing the classification task. \"\"\"\n    \n    model = Sequential([\n        Input(shape=(*IMAGE_SIZE, 3)),\n        Conv2D(16, 3, activation=act, padding='same'),\n        Conv2D(16, 3, activation=act, padding='same'),\n        MaxPool2D(),\n        conv_block(32),\n        conv_block(64),\n        conv_block(128),\n        Dropout(0.2),\n        conv_block(256),\n        Dropout(0.2),\n        Flatten(),\n        dense_block(512, 0.7),\n        dense_block(128, 0.5),\n        dense_block(64, 0.3),\n        Dense(4, activation='softmax')        \n    ], name = \"cnn_model\")\n\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Defining a custom callback function to stop training our model when accuracy goes above 99%\n\nclass MyCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if logs.get('val_acc') > 0.99:\n            print(\"\\nReached accuracy threshold! Terminating training.\")\n            self.model.stop_training = True\n            \nmy_callback = MyCallback()\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Defining other parameters for our CNN model\n\nmodel = construct_model()\n\nMETRICS = [tf.keras.metrics.CategoricalAccuracy(name='acc'),\n           tf.keras.metrics.AUC(name='auc'), \n           tfa.metrics.F1Score(num_classes=4)]\n\nCALLBACKS = [my_callback]\n    \nmodel.compile(optimizer='adam',\n              loss=tf.losses.CategoricalCrossentropy(),\n              metrics=METRICS)\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fit the training data to the model and validate it using the validation data\nEPOCHS = 50\n\nhistory = model.fit(train_data, train_labels, validation_data=(val_data, val_labels), callbacks=CALLBACKS, epochs=EPOCHS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_model_combined.save('/kaggle/working/cnn_custom_model_2', save_format='h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_input_dir = '/kaggle/input/models/cnn_custom_model_2'\ncurrent_model = tf.keras.models.load_model(model_input_dir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting the trend of the metrics during training\n\nfig, ax = plt.subplots(1, 3, figsize = (30, 5))\nax = ax.ravel()\n\nfor i, metric in enumerate([\"acc\", \"auc\", \"loss\"]):\n    ax[i].plot(history.history[metric])\n    ax[i].plot(history.history[\"val_\" + metric])\n    ax[i].set_title(\"Model {}\".format(metric))\n    ax[i].set_xlabel(\"Epochs\")\n    ax[i].set_ylabel(metric)\n    ax[i].legend([\"train\", \"val\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluating the model on the data\n\n#train_scores = model.evaluate(train_data, train_labels)\n# val_scores = model.evaluate(val_data, val_labels)\ntest_scores = model.evaluate(test_data, test_labels)\n\n#print(\"Training Accuracy: %.2f%%\"%(train_scores[1] * 100))\n# print(\"Validation Accuracy: %.2f%%\"%(val_scores[1] * 100))\nprint(\"Testing Accuracy: %.2f%%\"%(test_scores[1] * 100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = current_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predicting the test data\n\npred_labels = model.predict(test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print the classification report of the tested data\n\n#Since the labels are softmax arrays, we need to roundoff to have it in the form of 0s and 1s,\n#similar to the test_labels\ndef roundoff(arr):\n    \"\"\"To round off according to the argmax of each predicted label array. \"\"\"\n    arr[np.argwhere(arr != arr.max())] = 0\n    arr[np.argwhere(arr == arr.max())] = 1\n    return arr\n\nfor labels in pred_labels:\n    labels = roundoff(labels)\n\nprint(classification_report(test_labels, pred_labels, target_names=CLASSES))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plot the confusion matrix to understand the classification in detail\n\npred_ls = np.argmax(pred_labels, axis=1)\ntest_ls = np.argmax(test_labels, axis=1)\n\nconf_arr = confusion_matrix(test_ls, pred_ls)\n\nplt.figure(figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n\nax = sns.heatmap(conf_arr, cmap='Reds', annot=True, fmt='d', xticklabels=CLASSES, yticklabels=CLASSES)\n\nplt.title('Dementia\\'s Diagnosis')\nplt.xlabel('Prediction')\nplt.ylabel('Truth')\nplt.show(ax)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Printing some other classification metrics\n\nprint(\"Balanced Accuracy Score: {} %\".format(round(BAS(test_ls, pred_ls) * 100, 2)))\nprint(\"Matthew's Correlation Coefficient: {} %\".format(round(MCC(test_ls, pred_ls) * 100, 2)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_input_dir = '/kaggle/input/models/cnn_custom_model_2'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_dir = '/kaggle/working/cnn_custom_model_2'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_input_dir = '/kaggle/input/models/cnn_custom_model_2'\ncurrent_model = tf.keras.models.load_model(model_input_dir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check its architecture\nplot_model(current_model, to_file=model_dir + '.png', show_shapes=True, show_layer_names=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**TEST**","metadata":{}},{"cell_type":"code","source":"custom_model_combined = Sequential([\n    Input(shape=(*IMAGE_SIZE, 3)),\n    Conv2D(16, 3, activation='relu', padding='same'),\n    Conv2D(16, 3, activation='relu', padding='same'),\n    MaxPool2D(),\n    Conv2D(32, 3, activation='relu', padding='same'),\n    Conv2D(32, 3, activation='relu', padding='same'),\n    BatchNormalization(),\n    MaxPool2D(),\n    Conv2D(64, 3, activation='relu', padding='same'),\n    Conv2D(64, 3, activation='relu', padding='same'),\n    BatchNormalization(),\n    MaxPool2D(),\n    Conv2D(128, 3, activation='relu', padding='same'),\n    Conv2D(128, 3, activation='relu', padding='same'),\n    BatchNormalization(),\n    MaxPool2D(),\n    Conv2D(256, 3, activation='relu', padding='same'),\n    Conv2D(256, 3, activation='relu', padding='same', name = 'last_conv_layer'),\n    BatchNormalization(),\n    MaxPool2D(),\n    Flatten(),\n    Dropout(0.2),\n    Dense(512, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.7),\n    Dense(128, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.5),\n    Dense(64, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.3),\n    Dense(4, activation='softmax')        \n], name = \"cnn_model\")\n\ncustom_model_combined.summary(line_length=100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fit the training data to the model and validate it using the validation data\nEPOCHS = 50\n\nhistory = custom_model_combined.fit(train_data, train_labels, validation_data=(val_data, val_labels), callbacks=CALLBACKS, epochs=EPOCHS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_model_combined_history = history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_model_combined.save('/kaggle/working/custom_model_v2', save_format='h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting the trend of the metrics during training\n\nfig, ax = plt.subplots(1, 3, figsize = (30, 5))\nax = ax.ravel()\n\nfor i, metric in enumerate([\"acc\", \"auc\", \"loss\"]):\n    ax[i].plot(custom_model_combined_history.history[metric])\n    ax[i].plot(custom_model_combined_history.history[\"val_\" + metric])\n    ax[i].set_title(\"Model {}\".format(metric))\n    ax[i].set_xlabel(\"Epochs\")\n    ax[i].set_ylabel(metric)\n    ax[i].legend([\"train\", \"val\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_model_combined = current_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluating the model on the data\n\n#train_scores = model.evaluate(train_data, train_labels)\n# val_scores = model.evaluate(val_data, val_labels)\ntest_scores = custom_model_combined.evaluate(test_data, test_labels)\n\n#print(\"Training Accuracy: %.2f%%\"%(train_scores[1] * 100))\n# print(\"Validation Accuracy: %.2f%%\"%(val_scores[1] * 100))\nprint(\"Testing Accuracy: %.2f%%\"%(test_scores[1] * 100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predicting the test data\n\npred_labels = custom_model_combined.predict(test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print the classification report of the tested data\n\n#Since the labels are softmax arrays, we need to roundoff to have it in the form of 0s and 1s,\n#similar to the test_labels\ndef roundoff(arr):\n    \"\"\"To round off according to the argmax of each predicted label array. \"\"\"\n    arr[np.argwhere(arr != arr.max())] = 0\n    arr[np.argwhere(arr == arr.max())] = 1\n    return arr\n\nfor labels in pred_labels:\n    labels = roundoff(labels)\n\nprint(classification_report(test_labels, pred_labels, target_names=CLASSES))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plot the confusion matrix to understand the classification in detail\n\npred_ls = np.argmax(pred_labels, axis=1)\ntest_ls = np.argmax(test_labels, axis=1)\n\nconf_arr = confusion_matrix(test_ls, pred_ls)\n\nplt.figure(figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n\nax = sns.heatmap(conf_arr, cmap='Greens', annot=True, fmt='d', xticklabels=CLASSES, yticklabels=CLASSES)\n\nplt.title('Dementia\\'s Diagnosis')\nplt.xlabel('Prediction')\nplt.ylabel('Truth')\nplt.show(ax)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Printing some other classification metrics\n\nprint(\"Balanced Accuracy Score: {} %\".format(round(BAS(test_ls, pred_ls) * 100, 2)))\nprint(\"Matthew's Correlation Coefficient: {} %\".format(round(MCC(test_ls, pred_ls) * 100, 2)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_dir = '/kaggle/input/models2/custom_model'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_dir = '/kaggle/working/custom_model'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"current_model = tf.keras.models.load_model(model_dir)\n\n#Check its architecture\nplot_model(current_model, to_file=output_dir + '.png', show_shapes=True, show_layer_names=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    \"/kaggle/input/test-images-2/Test2\",\n    seed=1337,\n    image_size=[180, 180],\n    batch_size=16,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classnames = train_ds.class_names\nlen(classnames),train_ds.class_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CLASSES = [ 'NonDemented',\n            'VeryMildDemented',\n            'MildDemented',\n            'ModerateDemented']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_IMAGES = []\n\nfor label in classnames:\n    dir_name = \"/kaggle/input/test-images-2/Test2/\" + label[:-2] +'ed'\n    NUM_IMAGES.append(len([name for name in os.listdir(dir_name)]))\n    \nNUM_IMAGES,classnames","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Performing Image Augmentation to have more data samples\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator as IDG\nIMG_SIZE = 180\nIMAGE_SIZE = [180, 180]\nDIM = (IMG_SIZE, IMG_SIZE)\nZOOM = [.99, 1.01]\nBRIGHT_RANGE = [0.8, 1.2]\nHORZ_FLIP = True\nFILL_MODE = \"constant\"\nDATA_FORMAT = \"channels_last\"\nWORK_DIR=\"/kaggle/input/test-images-2/Test2\"\nwork_dr = IDG(rescale = 1./255, brightness_range=BRIGHT_RANGE, zoom_range=ZOOM, data_format=DATA_FORMAT, fill_mode=FILL_MODE, horizontal_flip=HORZ_FLIP)\n\nnew_data_gen = work_dr.flow_from_directory(directory=WORK_DIR, target_size=DIM, batch_size=12, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_data, new_labels = new_data_gen.next()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(new_data.shape, new_labels.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path = '/kaggle/input/test-images-2/Test2/MildDemented/mildDem1.jpg'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_img(img_path, size):\n    img = tf.keras.preprocessing.image.load_img(img_path, target_size=size)\n    array = tf.keras.preprocessing.image.img_to_array(img)\n    array = np.expand_dims(array, axis=0)\n    return array","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = get_img(img_path, [180, 180])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_labels = custom_model_combined.predict(new_data)\n\n\ndef roundoff(arr):\n    \"\"\"To round off according to the argmax of each predicted label array.\"\"\"\n    arr[np.argwhere(arr != arr.max())] = 0\n    arr[np.argwhere(arr == arr.max())] = 1\n    return arr\n\nfor labels in pred_labels:\n    labels = roundoff(labels)\n    \npred = np.argmax(pred_labels,axis=1)\n\n# Map the label to respective classes\nlabels = (test_images.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npred = [labels[k] for k in pred]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_img_array(img_path, size):\n    img = tf.keras.preprocessing.image.load_img(img_path, target_size=size)\n    array = tf.keras.preprocessing.image.img_to_array(img)\n    # We add a dimension to transform our array into a \"batch\"\n    # of size \"size\"\n    array = np.expand_dims(array, axis=0)\n    return array\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    # First, we create a model that maps the input image to the activations\n    # of the last conv layer as well as the output predictions\n    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n                                      \n    # Then, we compute the gradient of the top predicted class for our input image\n    # with respect to the activations of the last conv layer\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n\n    # This is the gradient of the output neuron (top predicted or chosen)\n    # with regard to the output feature map of the last conv layer\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n\n    # This is a vector where each entry is the mean intensity of the gradient\n    # over a specific feature map channel\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    # We multiply each channel in the feature map array\n    # by \"how important this channel is\" with regard to the top predicted class\n    # then sum all the channels to obtain the heatmap class activation\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n\n    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()\n\ndef save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n    # Load the original image\n    img = tf.keras.preprocessing.image.load_img(img_path)\n    img = tf.keras.preprocessing.image.img_to_array(img)\n\n    # Rescale heatmap to a range 0-255\n    heatmap = np.uint8(255 * heatmap)\n\n    # Use jet colormap to colorize heatmap\n    jet = cm.get_cmap(\"jet\")\n\n    # Use RGB values of the colormap\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap]\n\n    # Create an image with RGB colorized heatmap\n    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n\n    # Superimpose the heatmap on original image\n    superimposed_img = jet_heatmap * alpha + img\n    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n\n    # Save the superimposed image\n    superimposed_img.save(cam_path)\n\n    # Display Grad CAM\n    # display(Image(cam_path))\n    \n    return cam_path\n\nimport matplotlib.cm as cm\nimg_size = IMAGE_SIZE\n\n# Remove last layer's softmax\ncustom_model_combined.layers[-1].activation = None\n\nlast_conv_layer_name = \"last_conv_layer\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\nlast_conv_layer_name = \"last_conv_layer\"\nheatmap = make_gradcam_heatmap(img, custom_model_combined, last_conv_layer_name)\ncam_path = save_and_display_gradcam(img_path, heatmap)\ncbar = plt.imshow(plt.imread(cam_path),cmap='jet')\nax.set_title(f\"Truth: {new_labels[0]}\\nPredicted: {pred[0]}\")\n\nplt.tight_layout()\ncbar_ax = fig.add_axes([1, 0.057, 0.05, 1.3])\nplt.colorbar(cbar, cax=cbar_ax)\nplt.savefig(\"grad_cam.jpg\")\nplt.subplots_adjust(left=0, bottom=0, right=1, top=1.4, wspace=0, hspace=0)\nplt.subplots_adjust(right=0.95)\nplt.show()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}